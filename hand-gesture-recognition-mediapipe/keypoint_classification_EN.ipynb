{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\reine\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\reine\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\reine\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\reine\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\reine\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "igMyGnjE9hEp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2HDvhIu9hEr"
   },
   "source": [
    "# Specify each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9NvZP2Zn9hEy"
   },
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5oMH7x19hEz"
   },
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "du4kodXL9hEz"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnL0uso9hEz"
   },
   "source": [
    "# Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QT5ZqtEz9hE0"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QmoKFsp49hE0"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xQU7JTZ_9hE0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxK_lETT9hE0"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vHBmUf1t9hE1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypqky9tc9hE1",
    "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m88\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,158</span> (4.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,158\u001b[0m (4.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,158</span> (4.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,158\u001b[0m (4.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MbMjOflQ9hE1"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c3Dac0M_9hE2"
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XI0j1Iu9hE2"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WirBl-JE9hE3",
    "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2113 - loss: 2.1192\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2214 - loss: 2.0956 - val_accuracy: 0.3333 - val_loss: 1.8680\n",
      "Epoch 2/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3115 - loss: 1.8637 \n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3126 - loss: 1.8566 - val_accuracy: 0.3736 - val_loss: 1.6934\n",
      "Epoch 3/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3486 - loss: 1.7177 \n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3484 - loss: 1.7170 - val_accuracy: 0.4249 - val_loss: 1.5887\n",
      "Epoch 4/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3820 - loss: 1.6364 \n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3803 - loss: 1.6375 - val_accuracy: 0.4891 - val_loss: 1.5011\n",
      "Epoch 5/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3874 - loss: 1.5989 \n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3879 - loss: 1.5987 - val_accuracy: 0.5342 - val_loss: 1.4313\n",
      "Epoch 6/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4282 - loss: 1.5212 \n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4278 - loss: 1.5214 - val_accuracy: 0.5622 - val_loss: 1.3560\n",
      "Epoch 7/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4337 - loss: 1.4978 \n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4339 - loss: 1.4973 - val_accuracy: 0.5820 - val_loss: 1.2859\n",
      "Epoch 8/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4570 - loss: 1.4283 \n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4576 - loss: 1.4271 - val_accuracy: 0.6209 - val_loss: 1.2108\n",
      "Epoch 9/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4801 - loss: 1.3633 \n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4804 - loss: 1.3625 - val_accuracy: 0.6387 - val_loss: 1.1399\n",
      "Epoch 10/1000\n",
      "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 1.3026\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4761 - loss: 1.3378 - val_accuracy: 0.6564 - val_loss: 1.0820\n",
      "Epoch 11/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4698 - loss: 1.3152 \n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4718 - loss: 1.3115 - val_accuracy: 0.6646 - val_loss: 1.0253\n",
      "Epoch 12/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 1.2439 \n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5147 - loss: 1.2434 - val_accuracy: 0.6694 - val_loss: 0.9770\n",
      "Epoch 13/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5110 - loss: 1.2226 \n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5118 - loss: 1.2210 - val_accuracy: 0.7117 - val_loss: 0.9328\n",
      "Epoch 14/1000\n",
      "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5076 - loss: 1.2131 \n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5151 - loss: 1.2009 - val_accuracy: 0.7555 - val_loss: 0.8855\n",
      "Epoch 15/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 1.1556 \n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5360 - loss: 1.1559 - val_accuracy: 0.7835 - val_loss: 0.8598\n",
      "Epoch 16/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5223 - loss: 1.1844 \n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5237 - loss: 1.1811 - val_accuracy: 0.7917 - val_loss: 0.8252\n",
      "Epoch 17/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5468 - loss: 1.1258 \n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5469 - loss: 1.1258 - val_accuracy: 0.7930 - val_loss: 0.7978\n",
      "Epoch 18/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5518 - loss: 1.1027 \n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5505 - loss: 1.1034 - val_accuracy: 0.7835 - val_loss: 0.7809\n",
      "Epoch 19/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 1.1064 \n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5590 - loss: 1.1057 - val_accuracy: 0.7794 - val_loss: 0.7588\n",
      "Epoch 20/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 1.0698 \n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5675 - loss: 1.0707 - val_accuracy: 0.7923 - val_loss: 0.7384\n",
      "Epoch 21/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5786 - loss: 1.0480 \n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5789 - loss: 1.0481 - val_accuracy: 0.7999 - val_loss: 0.7224\n",
      "Epoch 22/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 1.0622 \n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5694 - loss: 1.0620 - val_accuracy: 0.8012 - val_loss: 0.7106\n",
      "Epoch 23/1000\n",
      "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5547 - loss: 1.1172\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5698 - loss: 1.0500 - val_accuracy: 0.7978 - val_loss: 0.6957\n",
      "Epoch 24/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5861 - loss: 1.0194 \n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 1.0195 - val_accuracy: 0.8101 - val_loss: 0.6868\n",
      "Epoch 25/1000\n",
      "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5547 - loss: 1.1347\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5855 - loss: 1.0244 - val_accuracy: 0.8074 - val_loss: 0.6683\n",
      "Epoch 26/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 1.0053 \n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6004 - loss: 1.0053 - val_accuracy: 0.8340 - val_loss: 0.6562\n",
      "Epoch 27/1000\n",
      "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5234 - loss: 1.1223\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5793 - loss: 1.0272 - val_accuracy: 0.8470 - val_loss: 0.6471\n",
      "Epoch 28/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.9914 \n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6069 - loss: 0.9902 - val_accuracy: 0.8313 - val_loss: 0.6351\n",
      "Epoch 29/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.9930 \n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6115 - loss: 0.9909 - val_accuracy: 0.8511 - val_loss: 0.6302\n",
      "Epoch 30/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6052 - loss: 0.9532 \n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6049 - loss: 0.9546 - val_accuracy: 0.8538 - val_loss: 0.6162\n",
      "Epoch 31/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.9919 \n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6047 - loss: 0.9869 - val_accuracy: 0.8695 - val_loss: 0.6084\n",
      "Epoch 32/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.9506 \n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6233 - loss: 0.9517 - val_accuracy: 0.8723 - val_loss: 0.5989\n",
      "Epoch 33/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6412 - loss: 0.9199 \n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6407 - loss: 0.9213 - val_accuracy: 0.8654 - val_loss: 0.5864\n",
      "Epoch 34/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6129 - loss: 0.9636 \n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6136 - loss: 0.9621 - val_accuracy: 0.8757 - val_loss: 0.5792\n",
      "Epoch 35/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 0.9423 \n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.9398 - val_accuracy: 0.8750 - val_loss: 0.5700\n",
      "Epoch 36/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6337 - loss: 0.9362 \n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 0.9364 - val_accuracy: 0.8832 - val_loss: 0.5672\n",
      "Epoch 37/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6513 - loss: 0.9202 \n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6465 - loss: 0.9222 - val_accuracy: 0.8784 - val_loss: 0.5642\n",
      "Epoch 38/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 0.9304 \n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 0.9303 - val_accuracy: 0.8805 - val_loss: 0.5644\n",
      "Epoch 39/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6340 - loss: 0.9080 \n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6339 - loss: 0.9084 - val_accuracy: 0.8914 - val_loss: 0.5540\n",
      "Epoch 40/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 0.9043 \n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.9043 - val_accuracy: 0.8846 - val_loss: 0.5419\n",
      "Epoch 41/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6415 - loss: 0.9230 \n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6421 - loss: 0.9207 - val_accuracy: 0.8934 - val_loss: 0.5320\n",
      "Epoch 42/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6446 - loss: 0.8784 \n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.8791 - val_accuracy: 0.8921 - val_loss: 0.5227\n",
      "Epoch 43/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6578 - loss: 0.8688 \n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6578 - loss: 0.8699 - val_accuracy: 0.8955 - val_loss: 0.5165\n",
      "Epoch 44/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 0.8717 \n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6627 - loss: 0.8756 - val_accuracy: 0.9085 - val_loss: 0.5100\n",
      "Epoch 45/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6648 - loss: 0.8738 \n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6636 - loss: 0.8754 - val_accuracy: 0.9023 - val_loss: 0.5071\n",
      "Epoch 46/1000\n",
      "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.8589 \n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6688 - loss: 0.8663 - val_accuracy: 0.9030 - val_loss: 0.5079\n",
      "Epoch 47/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6395 - loss: 0.9354 \n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6406 - loss: 0.9295 - val_accuracy: 0.9173 - val_loss: 0.5064\n",
      "Epoch 48/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6485 - loss: 0.8937 \n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6492 - loss: 0.8923 - val_accuracy: 0.9051 - val_loss: 0.5034\n",
      "Epoch 49/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 0.8601 \n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6708 - loss: 0.8593 - val_accuracy: 0.9249 - val_loss: 0.4880\n",
      "Epoch 50/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6633 - loss: 0.8645 \n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6625 - loss: 0.8631 - val_accuracy: 0.9180 - val_loss: 0.4832\n",
      "Epoch 51/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6521 - loss: 0.8852 \n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6534 - loss: 0.8833 - val_accuracy: 0.9160 - val_loss: 0.4836\n",
      "Epoch 52/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6558 - loss: 0.8819 \n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6584 - loss: 0.8777 - val_accuracy: 0.9249 - val_loss: 0.4754\n",
      "Epoch 53/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6740 - loss: 0.8553 \n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6746 - loss: 0.8539 - val_accuracy: 0.9255 - val_loss: 0.4691\n",
      "Epoch 54/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.8361 \n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6699 - loss: 0.8413 - val_accuracy: 0.9187 - val_loss: 0.4734\n",
      "Epoch 55/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.8593 \n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6737 - loss: 0.8593 - val_accuracy: 0.9255 - val_loss: 0.4672\n",
      "Epoch 56/1000\n",
      "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 0.9100 \n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6474 - loss: 0.8966 - val_accuracy: 0.9228 - val_loss: 0.4669\n",
      "Epoch 57/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6521 - loss: 0.8878 \n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6594 - loss: 0.8759 - val_accuracy: 0.9201 - val_loss: 0.4592\n",
      "Epoch 58/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6781 - loss: 0.8527 \n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6810 - loss: 0.8484 - val_accuracy: 0.9235 - val_loss: 0.4580\n",
      "Epoch 59/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.8645\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6639 - loss: 0.8639 - val_accuracy: 0.9249 - val_loss: 0.4544\n",
      "Epoch 60/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6740 - loss: 0.8496 \n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6745 - loss: 0.8474 - val_accuracy: 0.9283 - val_loss: 0.4501\n",
      "Epoch 61/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 0.8733 \n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6687 - loss: 0.8666 - val_accuracy: 0.9303 - val_loss: 0.4472\n",
      "Epoch 62/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.8511 \n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6842 - loss: 0.8468 - val_accuracy: 0.9331 - val_loss: 0.4433\n",
      "Epoch 63/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.8089 \n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6920 - loss: 0.8112 - val_accuracy: 0.9214 - val_loss: 0.4445\n",
      "Epoch 64/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6742 - loss: 0.8464 \n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6743 - loss: 0.8445 - val_accuracy: 0.9317 - val_loss: 0.4423\n",
      "Epoch 65/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 0.7992 \n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6910 - loss: 0.8011 - val_accuracy: 0.9276 - val_loss: 0.4360\n",
      "Epoch 66/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.8394 \n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6836 - loss: 0.8343 - val_accuracy: 0.9324 - val_loss: 0.4359\n",
      "Epoch 67/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7003 - loss: 0.8068 \n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6979 - loss: 0.8122 - val_accuracy: 0.9310 - val_loss: 0.4290\n",
      "Epoch 68/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6999 - loss: 0.8167 \n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.8147 - val_accuracy: 0.9276 - val_loss: 0.4267\n",
      "Epoch 69/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7035 - loss: 0.7516 \n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7015 - loss: 0.7646 - val_accuracy: 0.9344 - val_loss: 0.4214\n",
      "Epoch 70/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.8066 \n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.8070 - val_accuracy: 0.9365 - val_loss: 0.4183\n",
      "Epoch 71/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.7699 \n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7111 - loss: 0.7744 - val_accuracy: 0.9317 - val_loss: 0.4171\n",
      "Epoch 72/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8087 \n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.8067 - val_accuracy: 0.9303 - val_loss: 0.4141\n",
      "Epoch 73/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6857 - loss: 0.8020 \n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6869 - loss: 0.8034 - val_accuracy: 0.9331 - val_loss: 0.4095\n",
      "Epoch 74/1000\n",
      "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6859 - loss: 0.7828  \n",
      "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6920 - loss: 0.7879 - val_accuracy: 0.9235 - val_loss: 0.4065\n",
      "Epoch 75/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.7650 \n",
      "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7092 - loss: 0.7663 - val_accuracy: 0.9372 - val_loss: 0.4012\n",
      "Epoch 76/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.8144 \n",
      "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6866 - loss: 0.8109 - val_accuracy: 0.9324 - val_loss: 0.3984\n",
      "Epoch 77/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6981 - loss: 0.7834 \n",
      "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - loss: 0.7830 - val_accuracy: 0.9296 - val_loss: 0.3959\n",
      "Epoch 78/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 0.7814 \n",
      "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 0.7792 - val_accuracy: 0.9276 - val_loss: 0.3926\n",
      "Epoch 79/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 0.8312 \n",
      "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - loss: 0.8301 - val_accuracy: 0.9372 - val_loss: 0.3947\n",
      "Epoch 80/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.7983 \n",
      "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7016 - loss: 0.7970 - val_accuracy: 0.9331 - val_loss: 0.3938\n",
      "Epoch 81/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.7800 \n",
      "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7085 - loss: 0.7809 - val_accuracy: 0.9337 - val_loss: 0.3954\n",
      "Epoch 82/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.7912 \n",
      "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7007 - loss: 0.7902 - val_accuracy: 0.9392 - val_loss: 0.3919\n",
      "Epoch 83/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.7776 \n",
      "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7077 - loss: 0.7786 - val_accuracy: 0.9296 - val_loss: 0.3957\n",
      "Epoch 84/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.7699 \n",
      "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7033 - loss: 0.7697 - val_accuracy: 0.9406 - val_loss: 0.3893\n",
      "Epoch 85/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.7967 \n",
      "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7032 - loss: 0.7920 - val_accuracy: 0.9372 - val_loss: 0.3881\n",
      "Epoch 86/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.7703 \n",
      "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.7702 - val_accuracy: 0.9413 - val_loss: 0.3847\n",
      "Epoch 87/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.8101 \n",
      "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.7993 - val_accuracy: 0.9365 - val_loss: 0.3804\n",
      "Epoch 88/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.7594 \n",
      "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7113 - loss: 0.7600 - val_accuracy: 0.9406 - val_loss: 0.3829\n",
      "Epoch 89/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.7718 \n",
      "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.7701 - val_accuracy: 0.9440 - val_loss: 0.3729\n",
      "Epoch 90/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.7667 \n",
      "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.7641 - val_accuracy: 0.9372 - val_loss: 0.3808\n",
      "Epoch 91/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.7772 \n",
      "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.7759 - val_accuracy: 0.9413 - val_loss: 0.3604\n",
      "Epoch 92/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.7730 \n",
      "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7054 - loss: 0.7721 - val_accuracy: 0.9406 - val_loss: 0.3731\n",
      "Epoch 93/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.7945 \n",
      "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6962 - loss: 0.7877 - val_accuracy: 0.9399 - val_loss: 0.3695\n",
      "Epoch 94/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.7507 \n",
      "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7242 - loss: 0.7521 - val_accuracy: 0.9365 - val_loss: 0.3649\n",
      "Epoch 95/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.7382 \n",
      "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.7410 - val_accuracy: 0.9392 - val_loss: 0.3726\n",
      "Epoch 96/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.7557 \n",
      "Epoch 96: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7153 - loss: 0.7548 - val_accuracy: 0.9406 - val_loss: 0.3758\n",
      "Epoch 97/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.7468 \n",
      "Epoch 97: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 0.7475 - val_accuracy: 0.9392 - val_loss: 0.3668\n",
      "Epoch 98/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.7415 \n",
      "Epoch 98: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7307 - loss: 0.7426 - val_accuracy: 0.9392 - val_loss: 0.3651\n",
      "Epoch 99/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.7443 \n",
      "Epoch 99: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7229 - loss: 0.7417 - val_accuracy: 0.9406 - val_loss: 0.3586\n",
      "Epoch 100/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.7166 \n",
      "Epoch 100: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7318 - loss: 0.7250 - val_accuracy: 0.9399 - val_loss: 0.3611\n",
      "Epoch 101/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.7476 \n",
      "Epoch 101: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7182 - loss: 0.7460 - val_accuracy: 0.9447 - val_loss: 0.3549\n",
      "Epoch 102/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.7180 \n",
      "Epoch 102: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.7199 - val_accuracy: 0.9440 - val_loss: 0.3603\n",
      "Epoch 103/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.7340 \n",
      "Epoch 103: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7278 - loss: 0.7343 - val_accuracy: 0.9385 - val_loss: 0.3524\n",
      "Epoch 104/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.7416 \n",
      "Epoch 104: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.7416 - val_accuracy: 0.9426 - val_loss: 0.3610\n",
      "Epoch 105/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.7348 \n",
      "Epoch 105: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.7359 - val_accuracy: 0.9358 - val_loss: 0.3563\n",
      "Epoch 106/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.7253 \n",
      "Epoch 106: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7264 - loss: 0.7265 - val_accuracy: 0.9378 - val_loss: 0.3558\n",
      "Epoch 107/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.7634 \n",
      "Epoch 107: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.7606 - val_accuracy: 0.9351 - val_loss: 0.3541\n",
      "Epoch 108/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7558 - loss: 0.7126 \n",
      "Epoch 108: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7536 - loss: 0.7115 - val_accuracy: 0.9392 - val_loss: 0.3451\n",
      "Epoch 109/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.7033 \n",
      "Epoch 109: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.7044 - val_accuracy: 0.9365 - val_loss: 0.3444\n",
      "Epoch 110/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.7363 \n",
      "Epoch 110: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.7341 - val_accuracy: 0.9372 - val_loss: 0.3513\n",
      "Epoch 111/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7123 \n",
      "Epoch 111: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7356 - loss: 0.7137 - val_accuracy: 0.9447 - val_loss: 0.3415\n",
      "Epoch 112/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.7121 \n",
      "Epoch 112: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7443 - loss: 0.7137 - val_accuracy: 0.9385 - val_loss: 0.3422\n",
      "Epoch 113/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7175 - loss: 0.7396 \n",
      "Epoch 113: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.7388 - val_accuracy: 0.9433 - val_loss: 0.3425\n",
      "Epoch 114/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.6982 \n",
      "Epoch 114: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7424 - loss: 0.7009 - val_accuracy: 0.9433 - val_loss: 0.3398\n",
      "Epoch 115/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7607 \n",
      "Epoch 115: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7252 - loss: 0.7584 - val_accuracy: 0.9413 - val_loss: 0.3439\n",
      "Epoch 116/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7055 \n",
      "Epoch 116: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7231 - loss: 0.7068 - val_accuracy: 0.9378 - val_loss: 0.3390\n",
      "Epoch 117/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.7078 \n",
      "Epoch 117: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.7090 - val_accuracy: 0.9406 - val_loss: 0.3352\n",
      "Epoch 118/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.7291 \n",
      "Epoch 118: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.7284 - val_accuracy: 0.9413 - val_loss: 0.3314\n",
      "Epoch 119/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.7256 \n",
      "Epoch 119: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.7264 - val_accuracy: 0.9413 - val_loss: 0.3413\n",
      "Epoch 120/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.7467 \n",
      "Epoch 120: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.7441 - val_accuracy: 0.9399 - val_loss: 0.3420\n",
      "Epoch 121/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.6925 \n",
      "Epoch 121: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7434 - loss: 0.6955 - val_accuracy: 0.9419 - val_loss: 0.3398\n",
      "Epoch 122/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.7140 \n",
      "Epoch 122: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7372 - loss: 0.7140 - val_accuracy: 0.9413 - val_loss: 0.3402\n",
      "Epoch 123/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.7469 \n",
      "Epoch 123: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.7438 - val_accuracy: 0.9433 - val_loss: 0.3317\n",
      "Epoch 124/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.7200 \n",
      "Epoch 124: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7322 - loss: 0.7203 - val_accuracy: 0.9378 - val_loss: 0.3396\n",
      "Epoch 125/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.7475 \n",
      "Epoch 125: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.7398 - val_accuracy: 0.9474 - val_loss: 0.3397\n",
      "Epoch 126/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7362 - loss: 0.7459 \n",
      "Epoch 126: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7377 - loss: 0.7391 - val_accuracy: 0.9344 - val_loss: 0.3417\n",
      "Epoch 127/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.7318 \n",
      "Epoch 127: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.7302 - val_accuracy: 0.9419 - val_loss: 0.3368\n",
      "Epoch 128/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.7200 \n",
      "Epoch 128: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7342 - loss: 0.7198 - val_accuracy: 0.9406 - val_loss: 0.3409\n",
      "Epoch 129/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7387 - loss: 0.6915 \n",
      "Epoch 129: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.6937 - val_accuracy: 0.9440 - val_loss: 0.3303\n",
      "Epoch 130/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.7204 \n",
      "Epoch 130: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7299 - loss: 0.7202 - val_accuracy: 0.9365 - val_loss: 0.3353\n",
      "Epoch 131/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.7257 \n",
      "Epoch 131: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7274 - loss: 0.7217 - val_accuracy: 0.9385 - val_loss: 0.3339\n",
      "Epoch 132/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.7057 \n",
      "Epoch 132: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7353 - loss: 0.7089 - val_accuracy: 0.9324 - val_loss: 0.3390\n",
      "Epoch 133/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.6866 \n",
      "Epoch 133: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7405 - loss: 0.6924 - val_accuracy: 0.9385 - val_loss: 0.3393\n",
      "Epoch 134/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.7035 \n",
      "Epoch 134: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7424 - loss: 0.7042 - val_accuracy: 0.9399 - val_loss: 0.3277\n",
      "Epoch 135/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.7073 \n",
      "Epoch 135: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7365 - loss: 0.7049 - val_accuracy: 0.9413 - val_loss: 0.3220\n",
      "Epoch 136/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 0.7227 \n",
      "Epoch 136: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7464 - loss: 0.7190 - val_accuracy: 0.9331 - val_loss: 0.3278\n",
      "Epoch 137/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.6998 \n",
      "Epoch 137: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7387 - loss: 0.7002 - val_accuracy: 0.9399 - val_loss: 0.3286\n",
      "Epoch 138/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.7247 \n",
      "Epoch 138: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7302 - loss: 0.7200 - val_accuracy: 0.9358 - val_loss: 0.3310\n",
      "Epoch 139/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.7174 \n",
      "Epoch 139: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7316 - loss: 0.7151 - val_accuracy: 0.9344 - val_loss: 0.3287\n",
      "Epoch 140/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.6858 \n",
      "Epoch 140: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7492 - loss: 0.6887 - val_accuracy: 0.9399 - val_loss: 0.3335\n",
      "Epoch 141/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6867 \n",
      "Epoch 141: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7452 - loss: 0.6857 - val_accuracy: 0.9337 - val_loss: 0.3279\n",
      "Epoch 142/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.7431 \n",
      "Epoch 142: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7269 - loss: 0.7395 - val_accuracy: 0.9385 - val_loss: 0.3344\n",
      "Epoch 143/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.6909 \n",
      "Epoch 143: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7407 - loss: 0.6936 - val_accuracy: 0.9324 - val_loss: 0.3346\n",
      "Epoch 144/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.7052 \n",
      "Epoch 144: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7497 - loss: 0.7049 - val_accuracy: 0.9358 - val_loss: 0.3300\n",
      "Epoch 145/1000\n",
      "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.7203 \n",
      "Epoch 145: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7355 - loss: 0.7230 - val_accuracy: 0.9406 - val_loss: 0.3242\n",
      "Epoch 146/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6666 \n",
      "Epoch 146: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 0.6694 - val_accuracy: 0.9413 - val_loss: 0.3210\n",
      "Epoch 147/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.6935 \n",
      "Epoch 147: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7399 - loss: 0.6938 - val_accuracy: 0.9419 - val_loss: 0.3225\n",
      "Epoch 148/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.6537 \n",
      "Epoch 148: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7519 - loss: 0.6563 - val_accuracy: 0.9426 - val_loss: 0.3180\n",
      "Epoch 149/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.6920 \n",
      "Epoch 149: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.6907 - val_accuracy: 0.9426 - val_loss: 0.3294\n",
      "Epoch 150/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.6983 \n",
      "Epoch 150: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.6972 - val_accuracy: 0.9467 - val_loss: 0.3258\n",
      "Epoch 151/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.6764 \n",
      "Epoch 151: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7458 - loss: 0.6781 - val_accuracy: 0.9440 - val_loss: 0.3163\n",
      "Epoch 152/1000\n",
      "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.6915 \n",
      "Epoch 152: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7349 - loss: 0.6949 - val_accuracy: 0.9331 - val_loss: 0.3283\n",
      "Epoch 153/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.6844 \n",
      "Epoch 153: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.6860 - val_accuracy: 0.9385 - val_loss: 0.3188\n",
      "Epoch 154/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.6670 \n",
      "Epoch 154: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6679 - val_accuracy: 0.9372 - val_loss: 0.3183\n",
      "Epoch 155/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7519 - loss: 0.6777 \n",
      "Epoch 155: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7514 - loss: 0.6798 - val_accuracy: 0.9426 - val_loss: 0.3215\n",
      "Epoch 156/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.6592 \n",
      "Epoch 156: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7639 - loss: 0.6625 - val_accuracy: 0.9392 - val_loss: 0.3265\n",
      "Epoch 157/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.6956 \n",
      "Epoch 157: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7393 - loss: 0.6922 - val_accuracy: 0.9413 - val_loss: 0.3275\n",
      "Epoch 158/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7529 - loss: 0.6964 \n",
      "Epoch 158: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.6938 - val_accuracy: 0.9406 - val_loss: 0.3324\n",
      "Epoch 159/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.7053 \n",
      "Epoch 159: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7363 - loss: 0.7031 - val_accuracy: 0.9433 - val_loss: 0.3241\n",
      "Epoch 160/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7516 - loss: 0.6828 \n",
      "Epoch 160: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7511 - loss: 0.6847 - val_accuracy: 0.9406 - val_loss: 0.3274\n",
      "Epoch 161/1000\n",
      "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7507 - loss: 0.6844 \n",
      "Epoch 161: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7481 - loss: 0.6861 - val_accuracy: 0.9378 - val_loss: 0.3308\n",
      "Epoch 162/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 0.6930 \n",
      "Epoch 162: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7521 - loss: 0.6925 - val_accuracy: 0.9406 - val_loss: 0.3235\n",
      "Epoch 163/1000\n",
      "\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.6657 \n",
      "Epoch 163: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.6665 - val_accuracy: 0.9399 - val_loss: 0.3236\n",
      "Epoch 164/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.6850 \n",
      "Epoch 164: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.6840 - val_accuracy: 0.9419 - val_loss: 0.3196\n",
      "Epoch 165/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.6817 \n",
      "Epoch 165: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7481 - loss: 0.6830 - val_accuracy: 0.9372 - val_loss: 0.3228\n",
      "Epoch 166/1000\n",
      "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.7165 \n",
      "Epoch 166: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 0.7031 - val_accuracy: 0.9406 - val_loss: 0.3169\n",
      "Epoch 167/1000\n",
      "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7555 - loss: 0.6716 \n",
      "Epoch 167: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.6714 - val_accuracy: 0.9419 - val_loss: 0.3264\n",
      "Epoch 168/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.6751 \n",
      "Epoch 168: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7590 - loss: 0.6744 - val_accuracy: 0.9426 - val_loss: 0.3257\n",
      "Epoch 169/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7546 - loss: 0.6732 \n",
      "Epoch 169: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7546 - loss: 0.6724 - val_accuracy: 0.9406 - val_loss: 0.3147\n",
      "Epoch 170/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.6681 \n",
      "Epoch 170: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.6702 - val_accuracy: 0.9385 - val_loss: 0.3186\n",
      "Epoch 171/1000\n",
      "\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.6796 \n",
      "Epoch 171: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7506 - loss: 0.6766 - val_accuracy: 0.9426 - val_loss: 0.3133\n",
      "Epoch 172/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.6992 \n",
      "Epoch 172: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7430 - loss: 0.6956 - val_accuracy: 0.9406 - val_loss: 0.3123\n",
      "Epoch 173/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.6949 \n",
      "Epoch 173: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7395 - loss: 0.6885 - val_accuracy: 0.9447 - val_loss: 0.3139\n",
      "Epoch 174/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.6628 \n",
      "Epoch 174: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.6643 - val_accuracy: 0.9358 - val_loss: 0.3069\n",
      "Epoch 175/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.6784 \n",
      "Epoch 175: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.6789 - val_accuracy: 0.9317 - val_loss: 0.3301\n",
      "Epoch 176/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.6968 \n",
      "Epoch 176: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7465 - loss: 0.6951 - val_accuracy: 0.9351 - val_loss: 0.3229\n",
      "Epoch 177/1000\n",
      "\u001b[1m30/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.6781 \n",
      "Epoch 177: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.6756 - val_accuracy: 0.9324 - val_loss: 0.3227\n",
      "Epoch 178/1000\n",
      "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7734 - loss: 0.5845\n",
      "Epoch 178: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7593 - loss: 0.6464 - val_accuracy: 0.9399 - val_loss: 0.3159\n",
      "Epoch 179/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.6822 \n",
      "Epoch 179: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.6814 - val_accuracy: 0.9399 - val_loss: 0.3157\n",
      "Epoch 180/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7531 - loss: 0.6766 \n",
      "Epoch 180: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7505 - loss: 0.6792 - val_accuracy: 0.9419 - val_loss: 0.3146\n",
      "Epoch 181/1000\n",
      "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7682 - loss: 0.6395 \n",
      "Epoch 181: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.6397 - val_accuracy: 0.9372 - val_loss: 0.3177\n",
      "Epoch 182/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7526 - loss: 0.6640 \n",
      "Epoch 182: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7540 - loss: 0.6626 - val_accuracy: 0.9426 - val_loss: 0.3176\n",
      "Epoch 183/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.6926 \n",
      "Epoch 183: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 0.6908 - val_accuracy: 0.9392 - val_loss: 0.3222\n",
      "Epoch 184/1000\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.6623 \n",
      "Epoch 184: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7604 - loss: 0.6649 - val_accuracy: 0.9433 - val_loss: 0.3075\n",
      "Epoch 185/1000\n",
      "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.6588 \n",
      "Epoch 185: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7589 - loss: 0.6591 - val_accuracy: 0.9392 - val_loss: 0.3128\n",
      "Epoch 186/1000\n",
      "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7637 - loss: 0.6504 \n",
      "Epoch 186: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7584 - loss: 0.6636 - val_accuracy: 0.9413 - val_loss: 0.3223\n",
      "Epoch 187/1000\n",
      "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.6745 \n",
      "Epoch 187: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7540 - loss: 0.6719 - val_accuracy: 0.9378 - val_loss: 0.3150\n",
      "Epoch 188/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.6128 \n",
      "Epoch 188: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7615 - loss: 0.6230 - val_accuracy: 0.9365 - val_loss: 0.3193\n",
      "Epoch 189/1000\n",
      "\u001b[1m28/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.6627 \n",
      "Epoch 189: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7663 - loss: 0.6632 - val_accuracy: 0.9344 - val_loss: 0.3191\n",
      "Epoch 190/1000\n",
      "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.6553 \n",
      "Epoch 190: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.6574 - val_accuracy: 0.9337 - val_loss: 0.3166\n",
      "Epoch 191/1000\n",
      "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.6631 \n",
      "Epoch 191: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7591 - loss: 0.6653 - val_accuracy: 0.9392 - val_loss: 0.3247\n",
      "Epoch 192/1000\n",
      "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7650 - loss: 0.6739 \n",
      "Epoch 192: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7615 - loss: 0.6690 - val_accuracy: 0.9337 - val_loss: 0.3165\n",
      "Epoch 193/1000\n",
      "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.6769 \n",
      "Epoch 193: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7560 - loss: 0.6769 - val_accuracy: 0.9358 - val_loss: 0.3183\n",
      "Epoch 194/1000\n",
      "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.6868 \n",
      "Epoch 194: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7472 - loss: 0.6821 - val_accuracy: 0.9406 - val_loss: 0.3125\n",
      "Epoch 194: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11e3dc5e510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxvb2Y299hE3",
    "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.3034 \n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RBkmDeUW9hE4"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFz9Tb0I9hE4",
    "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "[5.1015493e-02 1.9316548e-01 4.3849263e-01 6.1965324e-03 3.0753711e-01\n",
      " 2.3531148e-04 2.8319499e-03 5.2544096e-04]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3U4yNWx9hE4"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "AP1V6SCk9hE5",
    "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       400\n",
      "           1       0.96      0.94      0.95       394\n",
      "           2       0.93      0.96      0.94       320\n",
      "           3       0.99      0.99      0.99        84\n",
      "           4       0.98      0.95      0.96        95\n",
      "           5       0.79      0.94      0.86        36\n",
      "           6       0.80      0.98      0.88       132\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94      1464\n",
      "   macro avg       0.80      0.83      0.82      1464\n",
      "weighted avg       0.94      0.94      0.94      1464\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reine\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\reine\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\reine\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNP6aqzc9hE5"
   },
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ODjnYyld9hE6"
   },
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRfuK8Y59hE6",
    "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\reine\\AppData\\Local\\Temp\\tmpt2vtiixz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\reine\\AppData\\Local\\Temp\\tmpt2vtiixz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\reine\\AppData\\Local\\Temp\\tmpt2vtiixz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1229397083920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1229397088912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1229397089488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1229397092368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1229397090256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1229397098128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6732"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHBPBXdx9hE6"
   },
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mGAzLocO9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oQuDK8YS9hE7"
   },
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2_ixAf_l9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4FoAnuc9hE7",
    "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vONjp19J9hE8",
    "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1015481e-02 1.9316542e-01 4.3849277e-01 6.1965310e-03 3.0753711e-01\n",
      " 2.3531145e-04 2.8319506e-03 5.2544079e-04]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keypoint_classification_EN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
